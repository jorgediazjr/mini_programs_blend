#!/usr/bin/python

import os, fnmatch, collections, argparse, random
import subprocess
from random import sample


def add_parser():
    parser = argparse.ArgumentParser(description="Program accepts short and tall height of cluster for extraction of promising clusters")
    parser.add_argument("-m", "--minimum", help="enter the minimum amount of datasets you want per cluster",
                        type=int)
    parser.add_argument("-x", "--maximum", help="enter the maximum number of datasets you want per cluster",
                        type=int)
    parser.add_argument("-r", "--random_clusters", help="number of random cluster user desires",
                        type=int, default=15)
    args = parser.parse_args()
    return args


def find_files(root_path, pattern):
    '''
    this function finds the locations
    of the files with the specified
    pattern

    Parameters
    ----------
    pattern: str
        the pattern for the filename
    path: str
        the home or root path of use

    Returns
    -------
    list
        list of paths to CLUSTERS.txt
    '''
    f = []
    for root, dirs, files in os.walk(root_path):
        for name in files:
            if fnmatch.fnmatch(name, pattern):
                f.append(os.path.join(root, name))
    return f


def file_lens(files):
    lens = {}
    for file in files:
        p = subprocess.Popen(['wc', '-l', file],
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE)
        result, error = p.communicate()
        if p.returncode == 0:
            num_of_clusters = int(result.strip().split()[0]) - 4
            lens[file] = num_of_clusters
    return lens


def read_header(files):
    '''
    this function just reads the
    header for CLUSTERS.txt

    Returns
    -------
    list
        list with all the header info 
    '''
    header = []
    for file in files:
        f = open(file, 'r').readlines()
        header.append(f[0])
        header.append(f[1])
        header.append(f[2])
        break
    return header


def generate_random_cluster_sets(lengths, mini=10, maxi=12, num_of_clusters=20):
    random_clusters = {}
    for path in lengths:
        num_lines = lengths[path]
        for i in range(num_of_clusters):
            random_clusters[i+1] = random.sample(range(1,num_lines), random.randint(mini, maxi+1))
    return random_clusters 


def get_random_clusters(lengths, num_of_clusters, cluster_files, mini, maxi):
    print("MINI={}\nMAXI={}".format(mini, maxi))
    path_cluster = {}
    temp_clusters = []
    for cluster_file in cluster_files:
        rng = [i for i in range(1, lengths[cluster_file] + 1)]
        print("Rand sample = {}\nType = {}".format(rand_sample, type(rand_sample)))
        os.chdir(os.path.dirname(cluster_file))
        with open(cluster_file, 'r') as f:
            lines = f.readlines()
            last = lines[-1]
            for line in lines:
                rand_sample = sample(rng, num_clusters)
                while len(temp_clusters) < len(rand_sample):
                    if line is last:
                        f.seek(0)

                    try:
                        if type(int(float(line.split()[0]+'.'))) == type(0):
                            if mini and maxi:
                                cluster = int(float(line.split()[0]+'.'))
                                number_of_datasets = int(line.split()[1])
                                if cluster in rand_sample:
                                    if number_of_datasets >= mini and number_of_datasets <= maxi:
                                        temp_clusters.append(line)
                            elif mini and not maxi:
                                maxi = lengths[cluster_file]
                                cluster = int(float(line.split()[0]+'.'))
                                number_of_datasets = int(line.split()[1])
                                if cluster in rand_sample:
                                    if number_of_datasets >= mini and number_of_datasets <= maxi:
                                        temp_clusters.append(line)
                            elif not mini and maxi:
                                mini = 1
                                cluster = int(float(line.split()[0]+'.'))
                                number_of_datasets = int(line.split()[1])
                                if cluster in rand_sample:
                                    if number_of_datasets >= mini and number_of_datasets <= maxi:
                                        temp_clusters.append(line)
                            else:
                                cluster = int(float(line.split()[0]+'.'))
                                if cluster in rand_sample:
                                    temp_clusters.append(line)
                    except:
                        pass
        path_cluster[cluster_file] = temp_clusters
        temp_clusters = []
    return path_cluster


def write_random_clusters_to_file(path_clusters, header):
    for path in path_clusters:
        os.chdir(os.path.dirname(path))
        with open("RANDOM_CLUSTERS.txt", 'w') as file:
            for line in header:
                file.write("{}\n".format(line))
            for cluster in path_clusters[path]:
                file.write("{}\n".format(cluster))


def main():
    args = add_parser()
    mini = args.minimum
    maxi = args.maximum
    num_clusters = args.random_clusters

    home_path = os.getcwd()
    cluster_files = find_files(home_path, 'CLUSTERS.txt')
    cluster_files.sort()

    lengths = file_lens(cluster_files)

    header = read_header(cluster_files)
    # new version
    random_clusters = get_random_clusters(lengths, num_clusters, cluster_files, mini, maxi)
    write_random_clusters_to_file(random_clusters, header)


if __name__ == '__main__':
    main()
